server:
  port: 8088

spring:
  master:
    datasource:
      name: mysql
      type: com.alibaba.druid.pool.DruidDataSource
      driver-class-name: com.mysql.cj.jdbc.Driver
      url: jdbc:mysql://127.0.0.1:3306/Project?useUnicode=true&characterEncoding=utf8&characterSetResults=utf8
      username: root
      password: 123456
      initialSize: 10
      maxActive: 100
      minIdle: 10
      maxWait: 6000
  cluster:
    datasource:
      name: default
      type: com.clickhouse.jdbc.ClickHouseDataSource
      driver-class-name: com.clickhouse.jdbc.ClickHouseDriver
      url: jdbc:clickhouse://127.0.0.1:8123
      username: default
      password: 123456
      maxThreads: 100
  datasource:
    druid:
      filters: stat
      maxActive: 20
      initialSize: 1
      maxWait: 60000
      minIdle: 10
      maxIdle: 15
      timeBetweenEvictionRunsMillis: 60000
      minEvictableIdleTimeMillis: 300000
      validationQuery: SELECT 1
      testWhileIdle: true
      testOnBorrow: false
      testOnReturn: false
      maxOpenPreparedStatements: 20
      removeAbandoned: true
      removeAbandonedTimeout: 1800
      logAbandoned: true
      poolPreparedStatements: true
      maxPoolPreparedStatementPerConnectionSize: 20

  redis:
    database: 1  # Redis数据库索引（默认为0） # Redis数据库索引（默认为0）
    host: 127.0.0.1   # Redis服务器地址
    port: 6379     # Redis服务器连接端口
    password:    # Redis服务器连接密码（默认为空)
    timeout: 2000  # 连接超时时间（毫秒）
    jedis:
      pool:
        max-active: 100
        max-wait: 2000
        max-idle: 10
        min-idle: 10

  jackson:
    date-format: yyyy-MM-dd HH:mm:ss
    time-zone: GMT+8
  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 100MB


mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl

#kafka:
#  producer: #    bootstrap-servers: 10.124.143.138:9092
#    bootstrap-servers: 10.161.55.1:9092
#    batch-size: 16785                                   #一次最多发送数据量
#    retries: 0                                          #发送失败后的重复发送次数
#    backoff:
#      ms: 100
#    buffer-memory: 33554432                             #32M批处理缓冲区
#    linger: 1
#  consumer: #    bootstrap-servers: 10.124.143.138:9092
#    bootstrap-servers: 10.161.55.1:9092
#    auto-offset-reset: latest                           #最早未被消费的offset earliest
#    max-poll-records: 100                              #批量消费一次最大拉取的数据量
#    enable-auto-commit: false                           #是否开启自动提交
#    auto-commit-interval: 28000                         #自动提交的间隔时间
#    session-timeout: 29000                              #连接超时时间
#    max-partition-fetch-bytes: 10485760
#    fetch-min-bytes: 1048576
#    fetch-max-wait-ms: 1000
#  listener:
#    batch-listener: true                                #是否开启批量消费，true表示批量消费
#    concurrencys: 3,6                                  #设置消费的线程数
#    poll-timeout: 5000                                  #如果消息队列中没有消息，等待timeout毫秒后，调用poll()方法。如果队列中有消息，立即消费消息，每次消费的消息的多少可以通过max.poll.records配置。
#
#alert:
#  topic: js_alerterror_data
#  jsAlertGroup: js_alert_data_test
#  jsAlertStartup: false
#  result: js_alerterror_data_new

logging:
  group:
    database: com.alibaba.druid.pool.DruidDataSource
  level:
    root: info
    database: error
  file:
    name: server.log
  logback:
    rolling policy:
      file-name-pattern: server.%d.%i.log
      max-file-size: 10MB

